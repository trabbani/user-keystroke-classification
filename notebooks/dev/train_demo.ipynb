{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keystrokes.utils.path_utils import DATA_PREPROCESSED_FOLDER, ARTIFACTS_FOLDER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keystrokes.transformers.transpose_transformer import TransposeTransformer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples(example_type, set_type=\"train_set\"):\n",
    "    folder_path = DATA_PREPROCESSED_FOLDER / set_type/ \"features\" / example_type \n",
    "    csv_files = list(folder_path.glob('*.csv'))\n",
    "    return [pd.read_csv(f) for f in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy():\n",
    "    positive_dfs = load_examples('positive')\n",
    "    negative_dfs = load_examples('negative')\n",
    "\n",
    "    dfs = negative_dfs + positive_dfs\n",
    "    labels = [0]*len(negative_dfs) + [1]*len(positive_dfs)\n",
    "    return dfs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, labels = get_Xy()\n",
    "dfs, labels = shuffle(dfs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1000 2000\n",
      "2000 3000\n",
      "3000 4000\n",
      "4000 5000\n",
      "5000 6000\n",
      "6000 7000\n",
      "7000 8000\n",
      "8000 9000\n",
      "9000 10000\n",
      "10000 11000\n",
      "11000 12000\n",
      "12000 13000\n",
      "13000 14000\n",
      "14000 15000\n",
      "15000 16000\n",
      "16000 17000\n",
      "17000 18000\n",
      "18000 19000\n",
      "19000 20000\n",
      "20000 21000\n",
      "21000 22000\n",
      "22000 23000\n",
      "23000 24000\n",
      "24000 25000\n",
      "25000 26000\n",
      "26000 27000\n",
      "27000 28000\n",
      "28000 29000\n",
      "29000 30000\n",
      "30000 31000\n",
      "31000 32000\n",
      "32000 33000\n",
      "33000 34000\n",
      "34000 35000\n",
      "35000 36000\n",
      "36000 37000\n",
      "37000 38000\n",
      "38000 39000\n",
      "39000 40000\n",
      "40000 41000\n",
      "41000 42000\n",
      "42000 43000\n",
      "43000 44000\n",
      "44000 45000\n",
      "45000 46000\n",
      "46000 47000\n",
      "47000 48000\n",
      "48000 49000\n",
      "49000 50000\n",
      "50000 51000\n",
      "51000 52000\n",
      "52000 53000\n",
      "53000 54000\n",
      "54000 55000\n",
      "55000 56000\n",
      "56000 57000\n",
      "57000 58000\n",
      "58000 59000\n",
      "59000 60000\n",
      "60000 61000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "for batch_id in range(0, len(labels) + 1, batch_size):\n",
    "    transpose_transformer = TransposeTransformer(top_columns=2000)\n",
    "    print(batch_id, batch_id + batch_size)\n",
    "    X = transpose_transformer.fit_transform(dfs[batch_id : batch_id + batch_size])\n",
    "    y = labels[batch_id : batch_id + batch_size]\n",
    "    X = X.assign(labels=y)\n",
    "    X.to_csv(\n",
    "        DATA_PREPROCESSED_FOLDER / \"train_set\" / \"matrices\" / f\"batch_{batch_id}\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [pd.read_csv(f) for f in (DATA_PREPROCESSED_FOLDER / \"train_set\" / \"matrices\" ).glob('*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat(all_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_dfs['labels']\n",
    "all_dfs = all_dfs.drop(columns='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1000_features = all_dfs.sum().nlargest(1000).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top_1000_features, columns=[\"FeatName\"]).sort_values(\n",
    "    by=\"FeatName\"\n",
    ").reset_index(drop=True).to_csv(DATA_PREPROCESSED_FOLDER / \"train_set\" / 'top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_dfs[top_1000_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60024, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60024,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarek/github/user-keystroke-classification/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_transformer = TransposeTransformer(top_columns=1000)\n",
    "transpose_transformer.selected_columns_ = top_1000_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transpose_and_predict_pipeline = Pipeline([('transpose', transpose_transformer),\n",
    "    ('xgboost', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keystrokes.pipelines.feature_pipeline import preprocessing_pipeline\n",
    "pipeline = Pipeline(\n",
    "    [('preprocessing', preprocessing_pipeline),\n",
    "     ('transpose_and_predict', transpose_and_predict_pipeline)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/tarek/.keystrokes/data/artifacts/pipeline.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the pipeline\n",
    "dump(pipeline, ARTIFACTS_FOLDER / 'pipeline.joblib') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/tarek/.keystrokes/data/artifacts/transpose_and_predict_pipeline.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the pipeline\n",
    "dump(transpose_and_predict_pipeline, ARTIFACTS_FOLDER / 'transpose_and_predict_pipeline.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keystrokes.features.example_creation import ExampleCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ExampleCreator(sampling_start_index=10000, sampling_end_index=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 12.7min finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_user(user_id):\n",
    "    p = ec.create_positive_examples(user_id)\n",
    "    n = ec.create_negative_examples(user_id)\n",
    "    return p, n\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(process_user)(user_id) for user_id in range(10000, 11000))\n",
    "\n",
    "all_p = []\n",
    "all_n = []\n",
    "\n",
    "for res in results:\n",
    "    all_p.extend(res[0])\n",
    "    all_n.extend(res[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs, y_test = shuffle(all_p + all_n, [1]*len(all_p) + [0]*len(all_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Step 5: Make predictions and check the accuracy on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mpredict(all_pairs)\n\u001b[1;32m      3\u001b[0m \u001b[39m# y_pred_proba = model.predict_proba(X_test)[:,1]\u001b[39;00m\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/sklearn/pipeline.py:481\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(Xt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/sklearn/pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/keystrokes/transformers/transpose_transformer.py:32\u001b[0m, in \u001b[0;36mTransposeTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransposed_X_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# clear the stored dataframe to save memory\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m X_transformed\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose(X)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/keystrokes/transformers/transpose_transformer.py:66\u001b[0m, in \u001b[0;36mTransposeTransformer.transpose\u001b[0;34m(self, dfs, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m     transformed_data\u001b[39m.\u001b[39mappend(df_pivot)\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_columns_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m---> 66\u001b[0m         pd\u001b[39m.\u001b[39;49mconcat(transformed_data, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     67\u001b[0m         \u001b[39m.\u001b[39mreindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_columns_, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m         \u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat(transformed_data, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:241\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    239\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    242\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:575\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_concatenate_join_units\u001b[39m(join_units: \u001b[39mlist\u001b[39m[JoinUnit], copy: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[1;32m    572\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39m    Concatenate values from several join units along axis=1.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     empty_dtype \u001b[39m=\u001b[39m _get_empty_dtype(join_units)\n\u001b[1;32m    577\u001b[0m     has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[1;32m    578\u001b[0m     upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:660\u001b[0m, in \u001b[0;36m_get_empty_dtype\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[39mreturn\u001b[39;00m empty_dtype\n\u001b[1;32m    658\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[0;32m--> 660\u001b[0m dtypes \u001b[39m=\u001b[39m [unit\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m unit\u001b[39m.\u001b[39mis_na]\n\u001b[1;32m    661\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(dtypes):\n\u001b[1;32m    662\u001b[0m     dtypes \u001b[39m=\u001b[39m [unit\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units \u001b[39mif\u001b[39;00m unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:660\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[39mreturn\u001b[39;00m empty_dtype\n\u001b[1;32m    658\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[0;32m--> 660\u001b[0m dtypes \u001b[39m=\u001b[39m [unit\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m unit\u001b[39m.\u001b[39;49mis_na]\n\u001b[1;32m    661\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(dtypes):\n\u001b[1;32m    662\u001b[0m     dtypes \u001b[39m=\u001b[39m [unit\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units \u001b[39mif\u001b[39;00m unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:486\u001b[0m, in \u001b[0;36mJoinUnit.is_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(val) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m isna(val):\n\u001b[1;32m    484\u001b[0m     \u001b[39m# ideally isna_all would do this short-circuiting\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39;49m(isna_all(row) \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m values)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:486\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(val) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m isna(val):\n\u001b[1;32m    484\u001b[0m     \u001b[39m# ideally isna_all would do this short-circuiting\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(isna_all(row) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m values)\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:759\u001b[0m, in \u001b[0;36misna_all\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39m# error: Incompatible types in assignment (expression has type \"Callable[[Any],\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39m# Any]\", variable has type \"ufunc\")\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     checker \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: _isna_array(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    756\u001b[0m         x, inf_as_na\u001b[39m=\u001b[39mINF_AS_NA\n\u001b[1;32m    757\u001b[0m     )\n\u001b[0;32m--> 759\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39;49m(\n\u001b[1;32m    760\u001b[0m     checker(arr[i : i \u001b[39m+\u001b[39;49m chunk_len])\u001b[39m.\u001b[39;49mall() \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m0\u001b[39;49m, total_len, chunk_len)\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:760\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39m# error: Incompatible types in assignment (expression has type \"Callable[[Any],\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39m# Any]\", variable has type \"ufunc\")\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     checker \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: _isna_array(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    756\u001b[0m         x, inf_as_na\u001b[39m=\u001b[39mINF_AS_NA\n\u001b[1;32m    757\u001b[0m     )\n\u001b[1;32m    759\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m--> 760\u001b[0m     checker(arr[i : i \u001b[39m+\u001b[39;49m chunk_len])\u001b[39m.\u001b[39;49mall() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, total_len, chunk_len)\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m~/github/user-keystroke-classification/venv/lib/python3.10/site-packages/numpy/core/_methods.py:61\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39mwhere)\n\u001b[0;32m---> 61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_all\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     \u001b[39m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m where \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 5: Make predictions and check the accuracy on the test set\n",
    "y_pred = pipeline.predict(all_pairs)\n",
    "# y_pred_proba = model.predict_proba(all_pairs)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = [5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.append(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [5, 6]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
